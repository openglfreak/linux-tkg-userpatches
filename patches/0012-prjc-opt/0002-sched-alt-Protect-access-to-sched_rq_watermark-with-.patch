From f2a941f02ca4a80ae33429e416b2ac97b847ca59 Mon Sep 17 00:00:00 2001
From: Torge Matthies <openglfreak@googlemail.com>
Date: Mon, 22 Nov 2021 01:04:15 +0100
Subject: [PATCH 2/2] sched/alt: Protect access to sched_rq_watermark with a
 raw_spinlock.

Removes the need for the expensive atomics in the loops of
update_sched_rq_watermark.

Signed-off-by: Torge Matthies <openglfreak@googlemail.com>
---
 kernel/sched/alt_core.c | 9 +++++++--
 1 file changed, 7 insertions(+), 2 deletions(-)

diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index 7d926e8eab96..79864d649d0c 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -148,6 +148,7 @@ DEFINE_PER_CPU_SHARED_ALIGNED(struct rq, runqueues);
 static cpumask_t sched_sg_idle_mask ____cacheline_aligned_in_smp;
 #endif
 static cpumask_t sched_rq_watermark[SCHED_BITS] ____cacheline_aligned_in_smp;
+static DEFINE_RAW_SPINLOCK(sched_rq_watermark_lock);
 
 /* sched_queue related functions */
 static inline void sched_queue_init(struct sched_queue *q)
@@ -176,6 +177,7 @@ static inline void update_sched_rq_watermark(struct rq *rq)
 {
 	unsigned long watermark = find_first_bit(rq->queue.bitmap, SCHED_QUEUE_BITS);
 	unsigned long last_wm = rq->watermark;
+	unsigned long flags;
 	unsigned long i;
 	int cpu;
 
@@ -184,20 +186,22 @@ static inline void update_sched_rq_watermark(struct rq *rq)
 
 	rq->watermark = watermark;
 	cpu = cpu_of(rq);
+	raw_spin_lock_irqsave(&sched_rq_watermark_lock, flags);
 	if (watermark < last_wm) {
 		for (i = last_wm - watermark; i > 0; i--)
-			cpumask_clear_cpu(cpu, sched_rq_watermark + SCHED_BITS - 1 - (i + watermark));
+			__cpumask_clear_cpu(cpu, sched_rq_watermark + SCHED_BITS - 1 - (i + watermark));
 #ifdef CONFIG_SCHED_SMT
 		if (static_branch_likely(&sched_smt_present) &&
 		    IDLE_TASK_SCHED_PRIO == last_wm)
 			cpumask_andnot(&sched_sg_idle_mask,
 				       &sched_sg_idle_mask, cpu_smt_mask(cpu));
 #endif
+		raw_spin_unlock_irqrestore(&sched_rq_watermark_lock, flags);
 		return;
 	}
 	/* last_wm < watermark */
 	for (i = watermark - last_wm; i > 0; i--)
-		cpumask_set_cpu(cpu, sched_rq_watermark + SCHED_BITS - 1 - (i + last_wm));
+		__cpumask_set_cpu(cpu, sched_rq_watermark + SCHED_BITS - 1 - (i + last_wm));
 #ifdef CONFIG_SCHED_SMT
 	if (static_branch_likely(&sched_smt_present) &&
 	    IDLE_TASK_SCHED_PRIO == watermark) {
@@ -209,6 +213,7 @@ static inline void update_sched_rq_watermark(struct rq *rq)
 				   &sched_sg_idle_mask, cpu_smt_mask(cpu));
 	}
 #endif
+	raw_spin_unlock_irqrestore(&sched_rq_watermark_lock, flags);
 }
 
 /*
-- 
2.34.0

