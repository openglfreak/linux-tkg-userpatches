From patchwork Mon Aug 15 07:13:30 2022
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
X-Patchwork-Submitter: Yu Zhao <yuzhao@google.com>
X-Patchwork-Id: 12943198
Return-Path: <owner-linux-mm@kvack.org>
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	aws-us-west-2-korg-lkml-1.web.codeaurora.org
Received: from kanga.kvack.org (kanga.kvack.org [205.233.56.17])
	by smtp.lore.kernel.org (Postfix) with ESMTP id B77A7C00140
	for <linux-mm@archiver.kernel.org>; Mon, 15 Aug 2022 07:14:35 +0000 (UTC)
Received: by kanga.kvack.org (Postfix)
	id 1B8C26B0085; Mon, 15 Aug 2022 03:14:31 -0400 (EDT)
Received: by kanga.kvack.org (Postfix, from userid 40)
	id 0F3EF6B0087; Mon, 15 Aug 2022 03:14:31 -0400 (EDT)
X-Delivered-To: int-list-linux-mm@kvack.org
Received: by kanga.kvack.org (Postfix, from userid 63042)
	id ED49F8D0001; Mon, 15 Aug 2022 03:14:30 -0400 (EDT)
X-Delivered-To: linux-mm@kvack.org
Received: from relay.hostedemail.com (smtprelay0011.hostedemail.com
 [216.40.44.11])
	by kanga.kvack.org (Postfix) with ESMTP id D4DD16B0085
	for <linux-mm@kvack.org>; Mon, 15 Aug 2022 03:14:30 -0400 (EDT)
Received: from smtpin09.hostedemail.com (a10.router.float.18 [10.200.18.1])
	by unirelay05.hostedemail.com (Postfix) with ESMTP id B723B40D3C
	for <linux-mm@kvack.org>; Mon, 15 Aug 2022 07:14:30 +0000 (UTC)
X-FDA: 79800963900.09.4D77C76
Received: from mail-yw1-f202.google.com (mail-yw1-f202.google.com
 [209.85.128.202])
	by imf14.hostedemail.com (Postfix) with ESMTP id 547BE1001AA
	for <linux-mm@kvack.org>; Mon, 15 Aug 2022 07:14:30 +0000 (UTC)
Received: by mail-yw1-f202.google.com with SMTP id
 00721157ae682-32fd9b85c35so30836227b3.23
        for <linux-mm@kvack.org>; Mon, 15 Aug 2022 00:14:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20210112;
        h=content-transfer-encoding:cc:to:from:subject:references
         :mime-version:message-id:in-reply-to:date:from:to:cc;
        bh=ZVZnfUOowkkoPsI8h5bMF1in9hHbeOK510g3NynOpVI=;
        b=G+7/wtwFGz44gYsEx4BnZB/tufCcUsktz0CnefTEdu5QflQPVdJtDzg+lhOhC2eslS
         5EV+GqRnAlSCGaaNir/Uwe4V4LOS8MLSaPsPiU7NjH4MIFjRrXAfDGmVoVfJ//GQ556l
         A2hSH8z5PtRv0KUXtHBcEynh1iiqviKbgTUqImAlQK0aLxjH6byapkAXTkAN76rgsMvG
         uzSnWNQbwcIjxDSnpzxO1SnCebeBio07VwdTEEl9EEPm8oFN6NIalLRqf4CuhPTikyZe
         XUDVYs7oo6j9ZbsO6MFHqZfyd218jJE8yNmCViAi5BaRPE515XOjkyaAYUG+4Ygy8wDz
         Tiwg==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20210112;
        h=content-transfer-encoding:cc:to:from:subject:references
         :mime-version:message-id:in-reply-to:date:x-gm-message-state:from:to
         :cc;
        bh=ZVZnfUOowkkoPsI8h5bMF1in9hHbeOK510g3NynOpVI=;
        b=X1Crb+vJZVF5QsIWrzoqhI0vQDkbTXIaElmzQuhApRfezPvjqjOLeRup/UVEeDiIE7
         5v63xPdz2IF4EgcIOEmoFXcHTMDqIxau2teS64Nv0XlWmNYGckuFnPIlhVXSSGvVyEWi
         QquwhYx4J/cBOUXVlOu/ce1VoGQkqdpBOs14HbLdTnarylZCAt62PpSoXsKIkTDMzVnv
         dzuWv6XZCR/13h6TxqY0ERThxvUdbRuDJNc0uzHC/pbejox25qsXmr/8t9TNKuTD+N7x
         XAeRcFzTlWjNk6LkWB+uPBlhayJ8O9mimQcpyVDV9W4IbOR9mKePsSo1L7uF0VoxRbyG
         4Tag==
X-Gm-Message-State: ACgBeo3shVuBp2/6tgUIwkMmy8PvLIIOR6vrTu8V+8jKsCPCYkHlF538
	5j4l3mB/quDCmD9qVh7g37E9p7QAScY=
X-Google-Smtp-Source: 
 AA6agR5nBs6VfOw78IT5aTAEoBSIvIu3gVqPaKS2BwbV7jH3AoxMDc+MitmVIBBk/YEeJwQN0b04SoteyIQ=
X-Received: from yuzhao.bld.corp.google.com
 ([2620:15c:183:200:d91:5887:ac93:ddf0])
 (user=yuzhao job=sendgmr) by 2002:a81:6a06:0:b0:31f:3df9:ec10 with SMTP id
 f6-20020a816a06000000b0031f3df9ec10mr11850348ywc.223.1660547669627; Mon, 15
 Aug 2022 00:14:29 -0700 (PDT)
Date: Mon, 15 Aug 2022 01:13:30 -0600
In-Reply-To: <20220815071332.627393-1-yuzhao@google.com>
Message-Id: <20220815071332.627393-12-yuzhao@google.com>
Mime-Version: 1.0
References: <20220815071332.627393-1-yuzhao@google.com>
X-Mailer: git-send-email 2.37.1.595.g718a3a8f04-goog
Subject: [PATCH v14 11/14] mm: multi-gen LRU: thrashing prevention
From: Yu Zhao <yuzhao@google.com>
To: Andrew Morton <akpm@linux-foundation.org>
Cc: Andi Kleen <ak@linux.intel.com>,
 Aneesh Kumar <aneesh.kumar@linux.ibm.com>,
  Catalin Marinas <catalin.marinas@arm.com>,
 Dave Hansen <dave.hansen@linux.intel.com>,  Hillf Danton <hdanton@sina.com>,
 Jens Axboe <axboe@kernel.dk>, Johannes Weiner <hannes@cmpxchg.org>,
  Jonathan Corbet <corbet@lwn.net>,
 Linus Torvalds <torvalds@linux-foundation.org>,
  Matthew Wilcox <willy@infradead.org>, Mel Gorman <mgorman@suse.de>,
  Michael Larabel <Michael@michaellarabel.com>,
 Michal Hocko <mhocko@kernel.org>,  Mike Rapoport <rppt@kernel.org>,
 Peter Zijlstra <peterz@infradead.org>, Tejun Heo <tj@kernel.org>,
  Vlastimil Babka <vbabka@suse.cz>, Will Deacon <will@kernel.org>,
 linux-arm-kernel@lists.infradead.org,  linux-doc@vger.kernel.org,
 linux-kernel@vger.kernel.org, linux-mm@kvack.org,  x86@kernel.org,
 page-reclaim@google.com, Yu Zhao <yuzhao@google.com>,
  Brian Geffon <bgeffon@google.com>,
 Jan Alexander Steffens <heftig@archlinux.org>,
  Oleksandr Natalenko <oleksandr@natalenko.name>,
 Steven Barrett <steven@liquorix.net>,
  Suleiman Souhlal <suleiman@google.com>, Daniel Byrne <djbyrne@mtu.edu>,
 Donald Carr <d@chaos-reins.com>,
  " =?utf-8?q?Holger_Hoffst=C3=A4tte?= " <holger@applied-asynchrony.com>,
 Konstantin Kharlamov <Hi-Angel@yandex.ru>,
  Shuang Zhai <szhai2@cs.rochester.edu>, Sofia Trinh <sofia.trinh@edi.works>,
  Vaibhav Jain <vaibhav@linux.ibm.com>
ARC-Seal: i=1; s=arc-20220608; d=hostedemail.com; t=1660547670; a=rsa-sha256;
	cv=none;
	b=4fufMAJ8OZcKdeAROa9dhdG2+fAHmQmT3li/Ea2zsi0oz9Apppuvvu3uP2jlfjlmgjEVwA
	IMg22+anx9BeOzdmobBzGz9hVfrLrv0S6gYjmfvSwHWcMxCjRtla/PHpf5X4DoJdyLsbLA
	U3ysO8EpK22//lWsgNLg4GsTmfTUfeE=
ARC-Authentication-Results: i=1;
	imf14.hostedemail.com;
	dkim=pass header.d=google.com header.s=20210112 header.b="G+7/wtwF";
	dmarc=pass (policy=reject) header.from=google.com;
	spf=pass (imf14.hostedemail.com: domain of
 3VfL5YgYKCEA0w1jcqiqqing.eqonkpwz-oomxcem.qti@flex--yuzhao.bounces.google.com
 designates 209.85.128.202 as permitted sender)
 smtp.mailfrom=3VfL5YgYKCEA0w1jcqiqqing.eqonkpwz-oomxcem.qti@flex--yuzhao.bounces.google.com
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed;
 d=hostedemail.com;
	s=arc-20220608; t=1660547670;
	h=from:from:sender:reply-to:subject:subject:date:date:
	 message-id:message-id:to:to:cc:cc:mime-version:mime-version:
	 content-type:content-type:
	 content-transfer-encoding:content-transfer-encoding:
	 in-reply-to:in-reply-to:references:references:dkim-signature;
	bh=ZVZnfUOowkkoPsI8h5bMF1in9hHbeOK510g3NynOpVI=;
	b=6XL6k2ZZagYaRfGSAACyb5Kw8wjXEFmG2QsUTfiildQKuAkZMCz3a4DBT+YvhwghQ355Lm
	AFrWJxAV+SND3Ak72KkqhAp6T1VRDFDLyVwvBJnP+zlkFqgOwxQYZ1h9shxwmvkLkkN1Iv
	YMjqw6Cc8MZmRNdQaozI49g6vwep5Bc=
X-Rspamd-Server: rspam02
X-Rspamd-Queue-Id: 547BE1001AA
Authentication-Results: imf14.hostedemail.com;
	dkim=pass header.d=google.com header.s=20210112 header.b="G+7/wtwF";
	dmarc=pass (policy=reject) header.from=google.com;
	spf=pass (imf14.hostedemail.com: domain of
 3VfL5YgYKCEA0w1jcqiqqing.eqonkpwz-oomxcem.qti@flex--yuzhao.bounces.google.com
 designates 209.85.128.202 as permitted sender)
 smtp.mailfrom=3VfL5YgYKCEA0w1jcqiqqing.eqonkpwz-oomxcem.qti@flex--yuzhao.bounces.google.com
X-Stat-Signature: xmf6wrndrgy6s4ztm5shyh5pd1htfj6b
X-Rspam-User: 
X-HE-Tag: 1660547670-570953
X-Bogosity: Ham, tests=bogofilter, spamicity=0.000000, version=1.2.4
Sender: owner-linux-mm@kvack.org
Precedence: bulk
X-Loop: owner-majordomo@kvack.org
List-ID: <linux-mm.kvack.org>

Add /sys/kernel/mm/lru_gen/min_ttl_ms for thrashing prevention, as
requested by many desktop users [1].

When set to value N, it prevents the working set of N milliseconds
from getting evicted. The OOM killer is triggered if this working set
cannot be kept in memory. Based on the average human detectable lag
(~100ms), N=1000 usually eliminates intolerable lags due to thrashing.
Larger values like N=3000 make lags less noticeable at the risk of
premature OOM kills.

Compared with the size-based approach [2], this time-based approach
has the following advantages:
1. It is easier to configure because it is agnostic to applications
   and memory sizes.
2. It is more reliable because it is directly wired to the OOM killer.

[1] https://lore.kernel.org/r/Ydza%2FzXKY9ATRoh6@google.com/
[2] https://lore.kernel.org/r/20101028191523.GA14972@google.com/

Signed-off-by: Yu Zhao <yuzhao@google.com>
Acked-by: Brian Geffon <bgeffon@google.com>
Acked-by: Jan Alexander Steffens (heftig) <heftig@archlinux.org>
Acked-by: Oleksandr Natalenko <oleksandr@natalenko.name>
Acked-by: Steven Barrett <steven@liquorix.net>
Acked-by: Suleiman Souhlal <suleiman@google.com>
Tested-by: Daniel Byrne <djbyrne@mtu.edu>
Tested-by: Donald Carr <d@chaos-reins.com>
Tested-by: Holger Hoffst√§tte <holger@applied-asynchrony.com>
Tested-by: Konstantin Kharlamov <Hi-Angel@yandex.ru>
Tested-by: Shuang Zhai <szhai2@cs.rochester.edu>
Tested-by: Sofia Trinh <sofia.trinh@edi.works>
Tested-by: Vaibhav Jain <vaibhav@linux.ibm.com>
---
 include/linux/mmzone.h |  2 ++
 mm/vmscan.c            | 75 +++++++++++++++++++++++++++++++++++++++---
 2 files changed, 73 insertions(+), 4 deletions(-)

diff --git a/include/linux/mmzone.h b/include/linux/mmzone.h
index 7f8c529b46ad..2558b57a05bc 100644
--- a/include/linux/mmzone.h
+++ b/include/linux/mmzone.h
@@ -422,6 +422,8 @@ struct lru_gen_struct {
 	unsigned long max_seq;
 	/* the eviction increments the oldest generation numbers */
 	unsigned long min_seq[ANON_AND_FILE];
+	/* the birth time of each generation in jiffies */
+	unsigned long timestamps[MAX_NR_GENS];
 	/* the multi-gen LRU lists, lazily sorted on eviction */
 	struct list_head lists[MAX_NR_GENS][ANON_AND_FILE][MAX_NR_ZONES];
 	/* the multi-gen LRU sizes, eventually consistent */
diff --git a/mm/vmscan.c b/mm/vmscan.c
index 5502c553e32e..08727f3b7171 100644
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -4298,6 +4298,7 @@ static void inc_max_seq(struct lruvec *lruvec, bool can_swap)
 	for (type = 0; type < ANON_AND_FILE; type++)
 		reset_ctrl_pos(lruvec, type, false);
 
+	WRITE_ONCE(lrugen->timestamps[next], jiffies);
 	/* make sure preceding modifications appear */
 	smp_store_release(&lrugen->max_seq, lrugen->max_seq + 1);
 
@@ -4424,7 +4425,7 @@ static unsigned long get_nr_evictable(struct lruvec *lruvec, unsigned long max_s
 	return total;
 }
 
-static void age_lruvec(struct lruvec *lruvec, struct scan_control *sc)
+static bool age_lruvec(struct lruvec *lruvec, struct scan_control *sc, unsigned long min_ttl)
 {
 	bool need_aging;
 	unsigned long nr_to_scan;
@@ -4438,21 +4439,40 @@ static void age_lruvec(struct lruvec *lruvec, struct scan_control *sc)
 	mem_cgroup_calculate_protection(NULL, memcg);
 
 	if (mem_cgroup_below_min(memcg))
-		return;
+		return false;
 
 	nr_to_scan = get_nr_evictable(lruvec, max_seq, min_seq, swappiness, &need_aging);
 	if (!nr_to_scan)
-		return;
+		return false;
 
 	nr_to_scan >>= mem_cgroup_online(memcg) ? sc->priority : 0;
 
+	if (min_ttl) {
+		int gen = lru_gen_from_seq(min_seq[LRU_GEN_FILE]);
+		unsigned long birth = READ_ONCE(lruvec->lrugen.timestamps[gen]);
+
+		if (time_is_after_jiffies(birth + min_ttl))
+			return false;
+
+		/* the size is likely too small to be helpful */
+		if (!nr_to_scan && sc->priority != DEF_PRIORITY)
+			return false;
+	}
+
 	if (nr_to_scan && need_aging)
 		try_to_inc_max_seq(lruvec, max_seq, sc, swappiness);
+
+	return true;
 }
 
+/* to protect the working set of the last N jiffies */
+static unsigned long lru_gen_min_ttl __read_mostly;
+
 static void lru_gen_age_node(struct pglist_data *pgdat, struct scan_control *sc)
 {
 	struct mem_cgroup *memcg;
+	bool success = false;
+	unsigned long min_ttl = READ_ONCE(lru_gen_min_ttl);
 
 	VM_WARN_ON_ONCE(!current_is_kswapd());
 
@@ -4478,12 +4498,32 @@ static void lru_gen_age_node(struct pglist_data *pgdat, struct scan_control *sc)
 	do {
 		struct lruvec *lruvec = mem_cgroup_lruvec(memcg, pgdat);
 
-		age_lruvec(lruvec, sc);
+		if (age_lruvec(lruvec, sc, min_ttl))
+			success = true;
 
 		cond_resched();
 	} while ((memcg = mem_cgroup_iter(NULL, memcg, NULL)));
 
 	clear_mm_walk();
+
+	/* check the order to exclude compaction-induced reclaim */
+	if (success || !min_ttl || sc->order)
+		return;
+
+	/*
+	 * The main goal is to OOM kill if every generation from all memcgs is
+	 * younger than min_ttl. However, another possibility is all memcgs are
+	 * either below min or empty.
+	 */
+	if (mutex_trylock(&oom_lock)) {
+		struct oom_control oc = {
+			.gfp_mask = sc->gfp_mask,
+		};
+
+		out_of_memory(&oc);
+
+		mutex_unlock(&oom_lock);
+	}
 }
 
 /*
@@ -5210,6 +5250,28 @@ static void lru_gen_change_state(bool enabled)
  *                          sysfs interface
  ******************************************************************************/
 
+static ssize_t show_min_ttl(struct kobject *kobj, struct kobj_attribute *attr, char *buf)
+{
+	return sprintf(buf, "%u\n", jiffies_to_msecs(READ_ONCE(lru_gen_min_ttl)));
+}
+
+static ssize_t store_min_ttl(struct kobject *kobj, struct kobj_attribute *attr,
+			     const char *buf, size_t len)
+{
+	unsigned int msecs;
+
+	if (kstrtouint(buf, 0, &msecs))
+		return -EINVAL;
+
+	WRITE_ONCE(lru_gen_min_ttl, msecs_to_jiffies(msecs));
+
+	return len;
+}
+
+static struct kobj_attribute lru_gen_min_ttl_attr = __ATTR(
+	min_ttl_ms, 0644, show_min_ttl, store_min_ttl
+);
+
 static ssize_t show_enabled(struct kobject *kobj, struct kobj_attribute *attr, char *buf)
 {
 	unsigned int caps = 0;
@@ -5258,6 +5320,7 @@ static struct kobj_attribute lru_gen_enabled_attr = __ATTR(
 );
 
 static struct attribute *lru_gen_attrs[] = {
+	&lru_gen_min_ttl_attr.attr,
 	&lru_gen_enabled_attr.attr,
 	NULL
 };
@@ -5273,12 +5336,16 @@ static struct attribute_group lru_gen_attr_group = {
 
 void lru_gen_init_lruvec(struct lruvec *lruvec)
 {
+	int i;
 	int gen, type, zone;
 	struct lru_gen_struct *lrugen = &lruvec->lrugen;
 
 	lrugen->max_seq = MIN_NR_GENS + 1;
 	lrugen->enabled = lru_gen_enabled();
 
+	for (i = 0; i <= MIN_NR_GENS + 1; i++)
+		lrugen->timestamps[i] = jiffies;
+
 	for_each_gen_type_zone(gen, type, zone)
 		INIT_LIST_HEAD(&lrugen->lists[gen][type][zone]);
 

